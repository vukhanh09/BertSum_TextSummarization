{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BertSum Training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1erM0aH-0YUCFPwpqAZgqUgIgpeEkIzhT","authorship_tag":"ABX9TyNSkO/XbcoEZa8UMqof/sNK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7dbcf8d6b6c7442c9bd78c19592f3609":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8db84574896242c2903047dfb176e2c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e626975dd974d248f3d8fa11201862f","IPY_MODEL_97a766e782654c1eba0f0582216c122c"]}},"8db84574896242c2903047dfb176e2c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e626975dd974d248f3d8fa11201862f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f71a8e7c0b4473482bb3e27295f72eb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59490567977e4a649011bf0e2429cc87"}},"97a766e782654c1eba0f0582216c122c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c14224716d0841ebb4d26c931fbc981a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/? [09:04&lt;00:00,  2.18s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5aaac86ee1c74d6c90bc5c3fcdd8ff44"}},"6f71a8e7c0b4473482bb3e27295f72eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59490567977e4a649011bf0e2429cc87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c14224716d0841ebb4d26c931fbc981a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5aaac86ee1c74d6c90bc5c3fcdd8ff44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"fsGwFTgSdUo-"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq8UkX_zdMK4"},"source":["# datasets = torch.load(\"/content/drive/MyDrive/Pro2/databert\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-q8VLJ3ds6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622813079242,"user_tz":-420,"elapsed":8163,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"a66390d9-2e46-4cdc-ff94-f8368512120c"},"source":["import torch\n","import torch.nn as nn\n","!pip install pytorch_pretrained_bert\n","from pytorch_pretrained_bert import BertModel, BertConfig"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/02/d0e07f3782cc054269ae0649ab1e3a0205fee1168545d4e502e62c27ba7e/boto3-1.17.87-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 37.7MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Collecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n","\u001b[?25hCollecting botocore<1.21.0,>=1.20.87\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/5c/23301b0c674ad31e48cfe778059b199e869397447ada7556fcddac290dfe/botocore-1.20.87-py2.py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 36.4MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.87->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.87->boto3->pytorch_pretrained_bert) (1.15.0)\n","\u001b[31mERROR: botocore 1.20.87 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.17.87 botocore-1.20.87 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nHxenTSW5adp"},"source":["!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNf34N9sWqd6"},"source":["\"\"\" Optimizers class \"\"\"\n","import torch\n","import torch.optim as optim\n","from torch.nn.utils import clip_grad_norm_\n","\n","\n","# from onmt.utils import use_gpu\n","\n","\n","def use_gpu(opt):\n","    \"\"\"\n","    Creates a boolean if gpu used\n","    \"\"\"\n","    return (hasattr(opt, 'gpu_ranks') and len(opt.gpu_ranks) > 0) or \\\n","           (hasattr(opt, 'gpu') and opt.gpu > -1)\n","\n","\n","class MultipleOptimizer(object):\n","    \"\"\" Implement multiple optimizers needed for sparse adam \"\"\"\n","\n","    def __init__(self, op):\n","        \"\"\" ? \"\"\"\n","        self.optimizers = op\n","\n","    def zero_grad(self):\n","        \"\"\" ? \"\"\"\n","        for op in self.optimizers:\n","            op.zero_grad()\n","\n","    def step(self):\n","        \"\"\" ? \"\"\"\n","        for op in self.optimizers:\n","            op.step()\n","\n","    @property\n","    def state(self):\n","        \"\"\" ? \"\"\"\n","        return {k: v for op in self.optimizers for k, v in op.state.items()}\n","\n","    def state_dict(self):\n","        \"\"\" ? \"\"\"\n","        return [op.state_dict() for op in self.optimizers]\n","\n","    def load_state_dict(self, state_dicts):\n","        \"\"\" ? \"\"\"\n","        assert len(state_dicts) == len(self.optimizers)\n","        for i in range(len(state_dicts)):\n","            self.optimizers[i].load_state_dict(state_dicts[i])\n","\n","\n","class Optimizer(object):\n","    \"\"\"\n","    Controller class for optimization. Mostly a thin\n","    wrapper for `optim`, but also useful for implementing\n","    rate scheduling beyond what is currently available.\n","    Also implements necessary methods for training RNNs such\n","    as grad manipulations.\n","\n","    Args:\n","      method (:obj:`str`): one of [sgd, adagrad, adadelta, adam]\n","      lr (float): learning rate\n","      lr_decay (float, optional): learning rate decay multiplier\n","      start_decay_steps (int, optional): step to start learning rate decay\n","      beta1, beta2 (float, optional): parameters for adam\n","      adagrad_accum (float, optional): initialization parameter for adagrad\n","      decay_method (str, option): custom decay options\n","      warmup_steps (int, option): parameter for `noam` decay\n","\n","    We use the default parameters for Adam that are suggested by\n","    the original paper https://arxiv.org/pdf/1412.6980.pdf\n","    These values are also used by other established implementations,\n","    e.g. https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n","    https://keras.io/optimizers/\n","    Recently there are slightly different values used in the paper\n","    \"Attention is all you need\"\n","    https://arxiv.org/pdf/1706.03762.pdf, particularly the value beta2=0.98\n","    was used there however, beta2=0.999 is still arguably the more\n","    established value, so we use that here as well\n","    \"\"\"\n","\n","    def __init__(self, method, learning_rate, max_grad_norm,\n","                 lr_decay=1, start_decay_steps=None, decay_steps=None,\n","                 beta1=0.9, beta2=0.999,\n","                 adagrad_accum=0.0,\n","                 decay_method=None,\n","                 warmup_steps=4000\n","                 ):\n","        self.last_ppl = None\n","        self.learning_rate = learning_rate\n","        self.original_lr = learning_rate\n","        self.max_grad_norm = max_grad_norm\n","        self.method = method\n","        self.lr_decay = lr_decay\n","        self.start_decay_steps = start_decay_steps\n","        self.decay_steps = decay_steps\n","        self.start_decay = False\n","        self._step = 0\n","        self.betas = [beta1, beta2]\n","        self.adagrad_accum = adagrad_accum\n","        self.decay_method = decay_method\n","        self.warmup_steps = warmup_steps\n","\n","    def set_parameters(self, params):\n","        \"\"\" ? \"\"\"\n","        self.params = []\n","        self.sparse_params = []\n","        for k, p in params:\n","            if p.requires_grad:\n","                if self.method != 'sparseadam' or \"embed\" not in k:\n","                    self.params.append(p)\n","                else:\n","                    self.sparse_params.append(p)\n","        \n","        \n","        self.optimizer = optim.Adam(self.params, lr=self.learning_rate,\n","                                        betas=self.betas, eps=1e-9)\n","\n","    def _set_rate(self, learning_rate):\n","        self.learning_rate = learning_rate\n","        if self.method != 'sparseadam':\n","            self.optimizer.param_groups[0]['lr'] = self.learning_rate\n","        else:\n","            for op in self.optimizer.optimizers:\n","                op.param_groups[0]['lr'] = self.learning_rate\n","\n","    def step(self):\n","        \"\"\"Update the model parameters based on current gradients.\n","\n","        Optionally, will employ gradient modification or update learning\n","        rate.\n","        \"\"\"\n","        self._step += 1\n","\n","        # Decay method used in tensor2tensor.\n","        if self.decay_method == \"noam\":\n","            self._set_rate(\n","                self.original_lr *\n","\n","                 min(self._step ** (-0.5),\n","                     self._step * self.warmup_steps**(-1.5)))\n","\n","            # self._set_rate(self.original_lr *self.model_size ** (-0.5) *min(1.0, self._step / self.warmup_steps)*max(self._step, self.warmup_steps)**(-0.5))\n","        # Decay based on start_decay_steps every decay_steps\n","        else:\n","            if ((self.start_decay_steps is not None) and (\n","                     self._step >= self.start_decay_steps)):\n","                self.start_decay = True\n","            if self.start_decay:\n","                if ((self._step - self.start_decay_steps)\n","                   % self.decay_steps == 0):\n","                    self.learning_rate = self.learning_rate * self.lr_decay\n","\n","        if self.method != 'sparseadam':\n","            self.optimizer.param_groups[0]['lr'] = self.learning_rate\n","\n","        if self.max_grad_norm:\n","            clip_grad_norm_(self.params, self.max_grad_norm)\n","        self.optimizer.step()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eddA6qcWtgB"},"source":["import torch\n","import torch.nn as nn\n","from pytorch_pretrained_bert import BertModel, BertConfig\n","from torch.nn.init import xavier_uniform_\n","\n","# from models.encoder import TransformerInterEncoder, Classifier, RNNEncoder\n","# from models.optimizers import Optimizer\n","\n","def build_optim(train_from, model, checkpoint):\n","    \"\"\" Build optimizer \"\"\"\n","    saved_optimizer_state_dict = None\n","\n","    if train_from != '':\n","        optim = checkpoint['optim']\n","        saved_optimizer_state_dict = optim.optimizer.state_dict()\n","    else:\n","        print(456)\n","        optim = Optimizer(\n","            'adam', 2e-3, 0,\n","            beta1= 0.9, beta2=0.999,\n","            decay_method='noam',\n","            warmup_steps= 8000)\n","\n","    optim.set_parameters(list(model.named_parameters()))\n","\n","    if train_from != '':\n","        optim.optimizer.load_state_dict(saved_optimizer_state_dict)\n","        # if args.visible_gpus != '-1':\n","        #     for state in optim.optimizer.state.values():\n","        #         for k, v in state.items():\n","        #             if torch.is_tensor(v):\n","        #                 state[k] = v.cuda()\n","\n","        if (optim.method == 'adam') and (len(optim.optimizer.state) < 1):\n","            raise RuntimeError(\n","                \"Error: loaded Adam optimizer from existing model\" +\n","                \" but optimizer state is empty\")\n","\n","    return optim\n","# def build_optim(model, checkpoint):\n","#     \"\"\" Build optimizer \"\"\"\n","\n","#     optim = Optimizer(\n","#         'adam', 2e-3, 0,\n","#         beta1= 0.9, beta2=0.999,\n","#         decay_method='noam',\n","#         warmup_steps= 8000)\n","\n","#     optim.set_parameters(list(model.named_parameters()))\n","\n","\n","#     # if (optim.method == 'adam') and (len(optim.optimizer.state) < 1):\n","#     #     raise RuntimeError(\n","#     #         \"Error: loaded Adam optimizer from existing model\" +\n","#     #         \" but optimizer state is empty\")\n","\n","#     return optim\n","\n","class Classifier(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(Classifier, self).__init__()\n","        self.linear1 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x, mask_cls):\n","        h = self.linear1(x).squeeze(-1)\n","        sent_scores = self.sigmoid(h) * mask_cls.float()\n","        return sent_scores\n","class Bert(nn.Module):\n","    def __init__(self, temp_dir, load_pretrained_bert, bert_config):\n","        super(Bert, self).__init__()\n","        if(load_pretrained_bert):\n","            self.model = BertModel.from_pretrained('bert-base-uncased', cache_dir=temp_dir)\n","        else:\n","            self.model = BertModel(bert_config)\n","\n","    def forward(self, x, segs, mask):\n","        encoded_layers, _ = self.model(x, segs, attention_mask =mask)\n","        top_vec = encoded_layers[-1]\n","        return top_vec\n","\n","\n","temp_dir = '/content/drive/MyDrive/Pro2/temp'\n","class Summarizer(nn.Module):\n","    def __init__(self,device, load_pretrained_bert = False, bert_config = None):\n","        super(Summarizer, self).__init__()\n","        self.bert = Bert(temp_dir, load_pretrained_bert, bert_config)\n","        \n","        self.encoder = Classifier(self.bert.model.config.hidden_size)\n","        \n","\n","      \n","        for p in self.encoder.parameters():\n","            if p.dim() > 1:\n","                xavier_uniform_(p)\n","\n","        self.to(device)\n","    def load_cp(self, pt):\n","        self.load_state_dict(pt, strict=True)\n","\n","    def forward(self, x, segs, clss, mask, mask_cls, sentence_range=None):\n","\n","        top_vec = self.bert(x, segs, mask)\n","        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n","        sents_vec = sents_vec * mask_cls[:, :, None].float()\n","        sent_scores = self.encoder(sents_vec, mask_cls).squeeze(-1)\n","        return sent_scores, mask_cls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqS5FpWqWugr","executionInfo":{"status":"ok","timestamp":1622813102821,"user_tz":-420,"elapsed":2932,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"3ef27284-261a-4689-d9ee-fa6ab26cf70d"},"source":["!pip install tensorboardX"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n","\r\u001b[K     |██▊                             | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O1TIFNxuWv_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622813153716,"user_tz":-420,"elapsed":50901,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"92ad2793-36ba-491b-f423-fe77b7db4c00"},"source":["from __future__ import division\n","\n","import argparse\n","import glob\n","import os\n","import random\n","import signal\n","import time\n","\n","import torch\n","from pytorch_pretrained_bert import BertConfig\n","\n","import distributed\n","import torch_xla.utils.serialization as xser\n","import torch_xla.core.xla_model as xm\n","\n","\n","\n","def train(device,train_from):\n","\n","    model = Summarizer(device, load_pretrained_bert=True)\n","    \n","    if train_from != '':\n","        checkpoint = xser.load(train_from)\n","        model.load_cp(checkpoint)\n","        # optim = build_optim(train_from, model, checkpoint)\n","        checkpoint = 0\n","    # else:\n","    #     optim = build_optim(train_from,model, None)\n"," \n","    return model\n","    # model,optim\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n","WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n","WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n","WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"roXJ5BvYWxLB"},"source":["def convert(datasets):\n","    def _pad(data, pad_id, width=-1):\n","        if (width == -1):\n","            width = max(len(d) for d in data)\n","        rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n","        return rtn_data\n","    pre_src = [x['src'] for x in datasets[:]]\n","    pre_labels = [x['labels'] for x in datasets[:]]\n","    pre_segs = [x['segs'] for x in datasets[:]]\n","    pre_clss = [x['clss'] for x in datasets[:]]\n","    # src_txt = [x['src_txt'] for x in datasets[:]]\n","    # tgt_txt = [x['tgt_txt'] for x in datasets[:]]\n","\n","    src = torch.tensor(_pad(pre_src, 0))\n","\n","    labels = torch.tensor(_pad(pre_labels, 0))\n","    segs = torch.tensor(_pad(pre_segs, 0))\n","    mask = ~(src == 0)\n","\n","    clss = torch.tensor(_pad(pre_clss, -1))\n","    mask_cls = ~ (clss == -1)\n","    clss[clss == -1] = 0\n","\n","\n","\n","    return src, labels,segs,clss,mask,mask_cls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGAzTSzVW0c0"},"source":["datasets = torch.load('/content/drive/MyDrive/Pro2/databert')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xVmdrG5ffeVq"},"source":["Tách dữ liệu train và test"]},{"cell_type":"code","metadata":{"id":"tCP_sppwfcKe"},"source":["import random\n","random.shuffle(datasets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9ufEhQgW1Kd","executionInfo":{"status":"ok","timestamp":1626441913201,"user_tz":-420,"elapsed":630,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}}},"source":["datasets_test = datasets[:50000]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahIomGvqVOqz"},"source":["torch.save(datasets_test,'/content/drive/MyDrive/Pro2/databert_train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUpwq2lzVgW_"},"source":["torch.save(datasets[50000:],'/content/drive/MyDrive/Pro2/databert_test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyGA4eLnf-3h"},"source":["datasets_test = torch.load('/content/drive/MyDrive/Pro2/databert_train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtWgxTJCW2S6"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","src, labels,segs,clss,mask,mask_cls = convert(datasets_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lVJDVCLxuwc"},"source":["lenData = len(datasets_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQ1ak6DdW3F9"},"source":["batch_size = 10\n","train_data = TensorDataset(src, labels,segs,clss,mask,mask_cls)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njxCQCZGW4KH"},"source":[" def timeSince(since):\n","        now = time.time()\n","        s = now - since\n","        m = math.floor(s / 60)\n","        s -= m * 60\n","        return '%dm %ds' % (m, s)\n","\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    print(pred_flat.shape)\n","    print(labels_flat.shape)\n","    \n","    F1_score = f1_score(pred_flat, labels_flat, average='macro')\n","    \n","    return accuracy_score(pred_flat, labels_flat), F1_score\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcx_gAEOW5vH"},"source":["from tqdm import tqdm_notebook"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqJhIRp3nxwA"},"source":["from tqdm import tqdm_notebook\n","import torch_xla.utils.serialization as xser\n","path ='/content/drive/MyDrive/Pro2/WeightBert/bertWeight1'\n","checkpoint = xser.load(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Fa-FMopn5MF"},"source":["import torch\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from tqdm import tqdm_notebook\n","# import torch_xla.core.xla_model as xm\n","import torch_xla.core.xla_model as xm\n","import torch_xla.utils.serialization as xser\n","\n","\n","import torch_xla.distributed.parallel_loader as pl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5r4hgxwn7tl"},"source":["device = xm.xla_device()\n","model = train(device,'')\n","model.load_cp(checkpoint)\n","fn_loss = torch.nn.BCELoss(reduction='sum')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"noRECMPoZf6A"},"source":["  #  xm.save(model.state_dict(), path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HVqrBrkgb4k"},"source":["# Train model"]},{"cell_type":"code","metadata":{"id":"yZRs7Im9oKzk"},"source":["params = []\n","for k, p in list(model.named_parameters()):\n","      if p.requires_grad:\n","          params.append(p)\n","\n","bert_optim = optim.Adam(params, lr=2e-3, eps=1e-9)\n","bert_optim.param_groups[0]['lr'] = 2e-3\n","_step = 25000\n","warmup_steps= 4000\n","params = 0\n","bert_optim.param_groups[0]['lr'] = (2e-3) * min(_step ** (-0.5), _step * warmup_steps**(-1.5))\n","\n","\n","# model = model.to(device)\n","fn_loss = torch.nn.BCELoss(reduction='sum')\n","\n","\n","# _trainEpoch(device,model,bert_optim,fn_loss)\n","all_loss = []\n","epochs = 30\n","print_every = 20\n","plot_every = 20\n","dev = device\n","\n","\n","start = time.time()\n","res = 0\n","rows = 10\n","\n","\n","\n","curr_loss = 0\n","\n","minLoss = 10e9\n","\n","for epoch in range(epochs):\n","    print('epoch: ',epoch)\n","    # x = 0\n","\n","    para_train_loader = pl.ParallelLoader(train_dataloader, [device]).per_device_loader(device)\n","    for i, batch in tqdm_notebook(enumerate(para_train_loader)):\n","\n","        model.zero_grad()\n","        bert_optim.zero_grad()\n","\n","        src = batch[0].to(dev)\n","        labels = batch[1].to(dev)\n","        segs = batch[2].to(dev)\n","        clss = batch[3].to(dev)\n","        mask = batch[4].to(dev)\n","        mask_cls = batch[5].to(dev)\n","\n","\n","\n","        sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","\n","        \n","\n","        loss = fn_loss(sent_scores, labels.float())\n","        loss = (loss*mask.float()).sum()\n","\n","\n","\n","        (loss/loss.numel()).backward()\n","      \n","        # bert_optim.step()\n","        # if i % 150 ==0:\n","        #     _step += 1\n","        \n","        xm.optimizer_step(bert_optim, barrier=True)\n","        # xm.mark_step()\n","\n","        curr_loss+= loss.item()\n","        print(loss.item())\n","\n","\n","    all_loss.append(curr_loss/rows)\n","    print(curr_loss/rows)\n","\n","    curr_loss = 0\n","    # xm.save(model.state_dict(), path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4kotkstwAAH"},"source":["device = xm.xla_device()\n","model = train(device,'')\n","model.load_cp(checkpoint)\n","# model = model.to(device)\n","params = []\n","for k, p in list(model.named_parameters()):\n","      if p.requires_grad:\n","          params.append(p)\n","\n","bert_optim = optim.Adam(params, lr=2e-3, eps=1e-9)\n","bert_optim.param_groups[0]['lr'] = 2e-3\n","_step = 25000\n","warmup_steps= 4000\n","params = 0\n","\n","\n","# model = model.to(device)\n","fn_loss = torch.nn.BCELoss(reduction='sum')\n","\n","\n","# _trainEpoch(device,model,bert_optim,fn_loss)\n","all_loss = []\n","epochs = 500\n","print_every = 20\n","plot_every = 20\n","dev = device\n","\n","\n","start = time.time()\n","res = 0\n","rows = 20\n","\n","\n","\n","curr_loss = 0\n","\n","for epoch in range(epochs):\n","    print('epoch: ',epoch)\n","    # x = 0\n","\n","    para_train_loader = pl.ParallelLoader(train_dataloader, [device]).per_device_loader(device)\n","    for i, batch in tqdm_notebook(enumerate(para_train_loader)):\n","\n","        model.zero_grad()\n","        bert_optim.zero_grad()\n","\n","        src = batch[0].to(dev)\n","        labels = batch[1].to(dev)\n","        segs = batch[2].to(dev)\n","        clss = batch[3].to(dev)\n","        mask = batch[4].to(dev)\n","        mask_cls = batch[5].to(dev)\n","\n","\n","\n","        sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","\n","        \n","\n","        loss = fn_loss(sent_scores, labels.float())\n","        loss = (loss*mask.float()).sum()\n","\n","\n","        (loss/loss.numel()).backward()\n","      \n","        # bert_optim.step()\n","        if i % 150 ==0:\n","            _step += 1\n","        bert_optim.param_groups[0]['lr'] = (2e-3) * min(_step ** (-0.5), _step * warmup_steps**(-1.5))\n","        xm.optimizer_step(bert_optim, barrier=True)\n","        # xm.mark_step()\n","\n","        curr_loss+= loss.item()\n","\n","\n","    all_loss.append(curr_loss/rows)\n","    print(curr_loss/rows)\n","    curr_loss = 0\n","    # xm.save(model.state_dict(), path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WuryylR1h4uu"},"source":["# Train song song trên 8 TPU"]},{"cell_type":"code","metadata":{"id":"0bcyIdcXW99X"},"source":["import torch\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from tqdm import tqdm_notebook\n","# import torch_xla.core.xla_model as xm\n","import torch_xla.core.xla_model as xm\n","import torch_xla.utils.serialization as xser\n","\n","\n","import torch_xla.distributed.parallel_loader as pl\n","# path ='/content/drive/MyDrive/Pro2/WeightBert/bertWeight'\n","\n","def simple_map_fn(index, flags):\n","    print(1)\n","    device = xm.xla_device()\n","    model = train(device,'')\n","    model.load_cp(checkpoint)\n","    # model = model.to(device)\n","    params = []\n","    for k, p in list(model.named_parameters()):\n","            if p.requires_grad:\n","                params.append(p)\n","\n","    bert_optim = optim.Adam(params, lr=2e-3, eps=1e-9)\n","    bert_optim.param_groups[0]['lr'] = 2e-3\n","    _step = 1\n","    warmup_steps=4000\n","    params = 0\n","\n","\n","    # model = model.to(device)\n","    fn_loss = torch.nn.BCELoss(reduction='sum')\n","    \n","\n","    # _trainEpoch(device,model,bert_optim,fn_loss)\n","    all_loss = []\n","    epochs = 500\n","    print_every = 20\n","    plot_every = 20\n","    dev = device\n","\n","\n","    start = time.time()\n","    res = 0\n","    rows = lenData\n","\n","\n","\n","    curr_loss = 0\n","\n","    for epoch in range(epochs):\n","        print('epoch: ',epoch)\n","        # x = 0\n","\n","        para_train_loader = pl.ParallelLoader(train_dataloader, [device]).per_device_loader(device)\n","        for i, batch in tqdm_notebook(enumerate(para_train_loader)):\n","\n","            model.zero_grad()\n","            bert_optim.zero_grad()\n","\n","            src = batch[0].to(dev)\n","            labels = batch[1].to(dev)\n","            segs = batch[2].to(dev)\n","            clss = batch[3].to(dev)\n","            mask = batch[4].to(dev)\n","            mask_cls = batch[5].to(dev)\n","\n","\n","\n","            sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","\n","            \n","\n","            loss = fn_loss(sent_scores, labels.float())\n","            loss = (loss*mask.float()).sum()\n","\n","\n","            (loss/loss.numel()).backward()\n","          \n","            # bert_optim.step()\n","            _step += 1\n","            bert_optim.param_groups[0]['lr'] = (2e-3) * min(_step ** (-0.5), _step * warmup_steps**(-1.5))\n","            xm.optimizer_step(bert_optim, barrier=True)\n","            # xm.mark_step()\n","\n","            curr_loss+= loss.item()\n","      \n","\n","        all_loss.append(curr_loss/rows)\n","        print(curr_loss/rows)\n","\n","\n","        curr_loss = 0\n","        xm.save(model.state_dict(), path)\n","    print(\"Process\", index ,\"is using\", xm.xla_real_devices([str(device)])[0])\n","    xm.save(model.state_dict(), path) #save model\n","\n","\n","\n","    # checkpoint = {\n","    #         'model': model.state_dict(),\n","    #         'optim': bert_optim,\n","    # }\n","    # print('master1')\n","    \n","    # print(1)\n","    # xm.save(bert_optim, path + '1')\n","    xm.rendezvous('init')\n","\n","\n","flags = {}\n","# Note: Colab only supports start_method='fork'\n","xmp.spawn(simple_map_fn, args=(flags,), nprocs=8, start_method='fork')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOqLr2d-iHy5"},"source":["# Đánh giá hiệu suất"]},{"cell_type":"code","metadata":{"id":"5SdQA6-JCPub"},"source":["from tqdm import tqdm_notebook\n","import torch_xla.utils.serialization as xser\n","path ='/content/drive/MyDrive/Pro2/WeightBert/bertWeight1'\n","checkpoint = xser.load(path)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17X0E80Bfo-M"},"source":["import torch\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from tqdm import tqdm_notebook\n","# import torch_xla.core.xla_model as xm\n","import torch_xla.core.xla_model as xm\n","import torch_xla.utils.serialization as xser\n","\n","\n","import torch_xla.distributed.parallel_loader as pl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ebpBtXJAfpv9"},"source":["device = xm.xla_device()\n","model = train(device,'')\n","model.load_cp(checkpoint)\n","fn_loss = torch.nn.BCELoss(reduction='sum')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdKf3hxpfrL5"},"source":["def convert1(datasets):\n","    def _pad(data, pad_id, width=-1):\n","        if (width == -1):\n","            width = max(len(d) for d in data)\n","        rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n","        return rtn_data\n","    pre_src = [x['src'] for x in datasets[:]]\n","    pre_labels = [x['labels'] for x in datasets[:]]\n","    pre_segs = [x['segs'] for x in datasets[:]]\n","    pre_clss = [x['clss'] for x in datasets[:]]\n","    src_txt = [x['src_txt'] for x in datasets[:]]\n","    tgt_txt = [x['tgt_txt'] for x in datasets[:]]\n","\n","    src = torch.tensor(_pad(pre_src, 0))\n","\n","    labels = torch.tensor(_pad(pre_labels, 0))\n","    segs = torch.tensor(_pad(pre_segs, 0))\n","    mask = ~(src == 0)\n","\n","    clss = torch.tensor(_pad(pre_clss, -1))\n","    mask_cls = ~ (clss == -1)\n","    clss[clss == -1] = 0\n","\n","\n","\n","    return src, labels,segs,clss,mask,mask_cls,src_txt,tgt_txt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P33tDHBdftha"},"source":["datasets_test = torch.load('/content/drive/MyDrive/Pro2/databert_test')\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","src, labels,segs,clss,mask,mask_cls, src_txt, tgt_txt = convert1(datasets_test[0:25000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVQ-ymHDqb0F"},"source":["model.load_cp(checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpWSImKzaH--"},"source":["batch_size = 100\n","train_data = TensorDataset(src, labels,segs,clss,mask,mask_cls)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wMrEPngCaLLu"},"source":["can_path = '/content/drive/MyDrive/Pro2/ResultData/candidate'\n","gold_path='/content/drive/MyDrive/Pro2/ResultData/gold'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpLxbB0IaM_a","colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["7dbcf8d6b6c7442c9bd78c19592f3609","8db84574896242c2903047dfb176e2c7","6e626975dd974d248f3d8fa11201862f","97a766e782654c1eba0f0582216c122c","6f71a8e7c0b4473482bb3e27295f72eb","59490567977e4a649011bf0e2429cc87","c14224716d0841ebb4d26c931fbc981a","5aaac86ee1c74d6c90bc5c3fcdd8ff44"]},"executionInfo":{"status":"ok","timestamp":1622813806625,"user_tz":-420,"elapsed":544494,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"a38f4e0c-9be4-43f3-9620-4736e6ef71f8"},"source":["import numpy as np\n","def _get_ngrams(n, text):\n","            ngram_set = set()\n","            text_length = len(text)\n","            max_index_ngram_start = text_length - n\n","            for i in range(max_index_ngram_start + 1):\n","                ngram_set.add(tuple(text[i:i + n]))\n","            return ngram_set\n","\n","def _block_tri(c, p):\n","    tri_c = _get_ngrams(3, c.split())\n","    for s in p:\n","        tri_s = _get_ngrams(3, s.split())\n","        if len(tri_c.intersection(tri_s))>0:\n","            return True\n","    return False\n","list_selected_ids = []\n","with torch.no_grad():\n","  for step, batch in tqdm_notebook(enumerate(train_dataloader)):\n","\n","      \n","      gold = []\n","      pred = []\n","      src = batch[0].to(device)\n","      labels = batch[1].to(device)\n","      segs = batch[2].to(device)\n","      clss = batch[3].to(device)\n","      mask = batch[4].to(device)\n","      mask_cls = batch[5].to(device)\n","      sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","      \n","      \n","      loss = fn_loss(sent_scores, labels.float())\n","      loss = (loss * mask.float()).sum()\n","      # if step % 1000:\n","      #     print(loss.item()/100)\n","\n","      # batch_stats = Statistics(float(loss.cpu().data.numpy()), len(labels))\n","      # stats.update(batch_stats)\n","\n","      sent_scores = sent_scores + mask.float()\n","\n","      sent_scores = sent_scores.cpu().data.numpy()\n","      selected_ids = np.argsort(-sent_scores, 1)\n","      list_selected_ids.append(selected_ids)\n","      xm.mark_step()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dbcf8d6b6c7442c9bd78c19592f3609","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"faRtOTQlaUVz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622813807073,"user_tz":-420,"elapsed":457,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"7b88dd0d-7b91-4a89-f1f0-2c1401e6bb8f"},"source":["list_out = list_selected_ids[0]\n","for i, idx in enumerate(list_selected_ids[1:]):\n","    print(list_out.shape)\n","    print(idx.shape)\n","    list_out = np.concatenate((list_out,idx),axis=0)\n","list_out.shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(100, 47)\n","(100, 47)\n","(200, 47)\n","(100, 47)\n","(300, 47)\n","(100, 47)\n","(400, 47)\n","(100, 47)\n","(500, 47)\n","(100, 47)\n","(600, 47)\n","(100, 47)\n","(700, 47)\n","(100, 47)\n","(800, 47)\n","(100, 47)\n","(900, 47)\n","(100, 47)\n","(1000, 47)\n","(100, 47)\n","(1100, 47)\n","(100, 47)\n","(1200, 47)\n","(100, 47)\n","(1300, 47)\n","(100, 47)\n","(1400, 47)\n","(100, 47)\n","(1500, 47)\n","(100, 47)\n","(1600, 47)\n","(100, 47)\n","(1700, 47)\n","(100, 47)\n","(1800, 47)\n","(100, 47)\n","(1900, 47)\n","(100, 47)\n","(2000, 47)\n","(100, 47)\n","(2100, 47)\n","(100, 47)\n","(2200, 47)\n","(100, 47)\n","(2300, 47)\n","(100, 47)\n","(2400, 47)\n","(100, 47)\n","(2500, 47)\n","(100, 47)\n","(2600, 47)\n","(100, 47)\n","(2700, 47)\n","(100, 47)\n","(2800, 47)\n","(100, 47)\n","(2900, 47)\n","(100, 47)\n","(3000, 47)\n","(100, 47)\n","(3100, 47)\n","(100, 47)\n","(3200, 47)\n","(100, 47)\n","(3300, 47)\n","(100, 47)\n","(3400, 47)\n","(100, 47)\n","(3500, 47)\n","(100, 47)\n","(3600, 47)\n","(100, 47)\n","(3700, 47)\n","(100, 47)\n","(3800, 47)\n","(100, 47)\n","(3900, 47)\n","(100, 47)\n","(4000, 47)\n","(100, 47)\n","(4100, 47)\n","(100, 47)\n","(4200, 47)\n","(100, 47)\n","(4300, 47)\n","(100, 47)\n","(4400, 47)\n","(100, 47)\n","(4500, 47)\n","(100, 47)\n","(4600, 47)\n","(100, 47)\n","(4700, 47)\n","(100, 47)\n","(4800, 47)\n","(100, 47)\n","(4900, 47)\n","(100, 47)\n","(5000, 47)\n","(100, 47)\n","(5100, 47)\n","(100, 47)\n","(5200, 47)\n","(100, 47)\n","(5300, 47)\n","(100, 47)\n","(5400, 47)\n","(100, 47)\n","(5500, 47)\n","(100, 47)\n","(5600, 47)\n","(100, 47)\n","(5700, 47)\n","(100, 47)\n","(5800, 47)\n","(100, 47)\n","(5900, 47)\n","(100, 47)\n","(6000, 47)\n","(100, 47)\n","(6100, 47)\n","(100, 47)\n","(6200, 47)\n","(100, 47)\n","(6300, 47)\n","(100, 47)\n","(6400, 47)\n","(100, 47)\n","(6500, 47)\n","(100, 47)\n","(6600, 47)\n","(100, 47)\n","(6700, 47)\n","(100, 47)\n","(6800, 47)\n","(100, 47)\n","(6900, 47)\n","(100, 47)\n","(7000, 47)\n","(100, 47)\n","(7100, 47)\n","(100, 47)\n","(7200, 47)\n","(100, 47)\n","(7300, 47)\n","(100, 47)\n","(7400, 47)\n","(100, 47)\n","(7500, 47)\n","(100, 47)\n","(7600, 47)\n","(100, 47)\n","(7700, 47)\n","(100, 47)\n","(7800, 47)\n","(100, 47)\n","(7900, 47)\n","(100, 47)\n","(8000, 47)\n","(100, 47)\n","(8100, 47)\n","(100, 47)\n","(8200, 47)\n","(100, 47)\n","(8300, 47)\n","(100, 47)\n","(8400, 47)\n","(100, 47)\n","(8500, 47)\n","(100, 47)\n","(8600, 47)\n","(100, 47)\n","(8700, 47)\n","(100, 47)\n","(8800, 47)\n","(100, 47)\n","(8900, 47)\n","(100, 47)\n","(9000, 47)\n","(100, 47)\n","(9100, 47)\n","(100, 47)\n","(9200, 47)\n","(100, 47)\n","(9300, 47)\n","(100, 47)\n","(9400, 47)\n","(100, 47)\n","(9500, 47)\n","(100, 47)\n","(9600, 47)\n","(100, 47)\n","(9700, 47)\n","(100, 47)\n","(9800, 47)\n","(100, 47)\n","(9900, 47)\n","(100, 47)\n","(10000, 47)\n","(100, 47)\n","(10100, 47)\n","(100, 47)\n","(10200, 47)\n","(100, 47)\n","(10300, 47)\n","(100, 47)\n","(10400, 47)\n","(100, 47)\n","(10500, 47)\n","(100, 47)\n","(10600, 47)\n","(100, 47)\n","(10700, 47)\n","(100, 47)\n","(10800, 47)\n","(100, 47)\n","(10900, 47)\n","(100, 47)\n","(11000, 47)\n","(100, 47)\n","(11100, 47)\n","(100, 47)\n","(11200, 47)\n","(100, 47)\n","(11300, 47)\n","(100, 47)\n","(11400, 47)\n","(100, 47)\n","(11500, 47)\n","(100, 47)\n","(11600, 47)\n","(100, 47)\n","(11700, 47)\n","(100, 47)\n","(11800, 47)\n","(100, 47)\n","(11900, 47)\n","(100, 47)\n","(12000, 47)\n","(100, 47)\n","(12100, 47)\n","(100, 47)\n","(12200, 47)\n","(100, 47)\n","(12300, 47)\n","(100, 47)\n","(12400, 47)\n","(100, 47)\n","(12500, 47)\n","(100, 47)\n","(12600, 47)\n","(100, 47)\n","(12700, 47)\n","(100, 47)\n","(12800, 47)\n","(100, 47)\n","(12900, 47)\n","(100, 47)\n","(13000, 47)\n","(100, 47)\n","(13100, 47)\n","(100, 47)\n","(13200, 47)\n","(100, 47)\n","(13300, 47)\n","(100, 47)\n","(13400, 47)\n","(100, 47)\n","(13500, 47)\n","(100, 47)\n","(13600, 47)\n","(100, 47)\n","(13700, 47)\n","(100, 47)\n","(13800, 47)\n","(100, 47)\n","(13900, 47)\n","(100, 47)\n","(14000, 47)\n","(100, 47)\n","(14100, 47)\n","(100, 47)\n","(14200, 47)\n","(100, 47)\n","(14300, 47)\n","(100, 47)\n","(14400, 47)\n","(100, 47)\n","(14500, 47)\n","(100, 47)\n","(14600, 47)\n","(100, 47)\n","(14700, 47)\n","(100, 47)\n","(14800, 47)\n","(100, 47)\n","(14900, 47)\n","(100, 47)\n","(15000, 47)\n","(100, 47)\n","(15100, 47)\n","(100, 47)\n","(15200, 47)\n","(100, 47)\n","(15300, 47)\n","(100, 47)\n","(15400, 47)\n","(100, 47)\n","(15500, 47)\n","(100, 47)\n","(15600, 47)\n","(100, 47)\n","(15700, 47)\n","(100, 47)\n","(15800, 47)\n","(100, 47)\n","(15900, 47)\n","(100, 47)\n","(16000, 47)\n","(100, 47)\n","(16100, 47)\n","(100, 47)\n","(16200, 47)\n","(100, 47)\n","(16300, 47)\n","(100, 47)\n","(16400, 47)\n","(100, 47)\n","(16500, 47)\n","(100, 47)\n","(16600, 47)\n","(100, 47)\n","(16700, 47)\n","(100, 47)\n","(16800, 47)\n","(100, 47)\n","(16900, 47)\n","(100, 47)\n","(17000, 47)\n","(100, 47)\n","(17100, 47)\n","(100, 47)\n","(17200, 47)\n","(100, 47)\n","(17300, 47)\n","(100, 47)\n","(17400, 47)\n","(100, 47)\n","(17500, 47)\n","(100, 47)\n","(17600, 47)\n","(100, 47)\n","(17700, 47)\n","(100, 47)\n","(17800, 47)\n","(100, 47)\n","(17900, 47)\n","(100, 47)\n","(18000, 47)\n","(100, 47)\n","(18100, 47)\n","(100, 47)\n","(18200, 47)\n","(100, 47)\n","(18300, 47)\n","(100, 47)\n","(18400, 47)\n","(100, 47)\n","(18500, 47)\n","(100, 47)\n","(18600, 47)\n","(100, 47)\n","(18700, 47)\n","(100, 47)\n","(18800, 47)\n","(100, 47)\n","(18900, 47)\n","(100, 47)\n","(19000, 47)\n","(100, 47)\n","(19100, 47)\n","(100, 47)\n","(19200, 47)\n","(100, 47)\n","(19300, 47)\n","(100, 47)\n","(19400, 47)\n","(100, 47)\n","(19500, 47)\n","(100, 47)\n","(19600, 47)\n","(100, 47)\n","(19700, 47)\n","(100, 47)\n","(19800, 47)\n","(100, 47)\n","(19900, 47)\n","(100, 47)\n","(20000, 47)\n","(100, 47)\n","(20100, 47)\n","(100, 47)\n","(20200, 47)\n","(100, 47)\n","(20300, 47)\n","(100, 47)\n","(20400, 47)\n","(100, 47)\n","(20500, 47)\n","(100, 47)\n","(20600, 47)\n","(100, 47)\n","(20700, 47)\n","(100, 47)\n","(20800, 47)\n","(100, 47)\n","(20900, 47)\n","(100, 47)\n","(21000, 47)\n","(100, 47)\n","(21100, 47)\n","(100, 47)\n","(21200, 47)\n","(100, 47)\n","(21300, 47)\n","(100, 47)\n","(21400, 47)\n","(100, 47)\n","(21500, 47)\n","(100, 47)\n","(21600, 47)\n","(100, 47)\n","(21700, 47)\n","(100, 47)\n","(21800, 47)\n","(100, 47)\n","(21900, 47)\n","(100, 47)\n","(22000, 47)\n","(100, 47)\n","(22100, 47)\n","(100, 47)\n","(22200, 47)\n","(100, 47)\n","(22300, 47)\n","(100, 47)\n","(22400, 47)\n","(100, 47)\n","(22500, 47)\n","(100, 47)\n","(22600, 47)\n","(100, 47)\n","(22700, 47)\n","(100, 47)\n","(22800, 47)\n","(100, 47)\n","(22900, 47)\n","(100, 47)\n","(23000, 47)\n","(100, 47)\n","(23100, 47)\n","(100, 47)\n","(23200, 47)\n","(100, 47)\n","(23300, 47)\n","(100, 47)\n","(23400, 47)\n","(100, 47)\n","(23500, 47)\n","(100, 47)\n","(23600, 47)\n","(100, 47)\n","(23700, 47)\n","(100, 47)\n","(23800, 47)\n","(100, 47)\n","(23900, 47)\n","(100, 47)\n","(24000, 47)\n","(100, 47)\n","(24100, 47)\n","(100, 47)\n","(24200, 47)\n","(100, 47)\n","(24300, 47)\n","(100, 47)\n","(24400, 47)\n","(100, 47)\n","(24500, 47)\n","(100, 47)\n","(24600, 47)\n","(100, 47)\n","(24700, 47)\n","(100, 47)\n","(24800, 47)\n","(100, 47)\n","(24900, 47)\n","(100, 47)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(25000, 47)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"u8R2cSzxaYIt"},"source":["can_path = '/content/drive/MyDrive/Pro2/ResultData/candidate'\n","gold_path='/content/drive/MyDrive/Pro2/ResultData/gold'\n","pred_keys = []\n","with open(can_path, 'w') as save_pred:\n","    with open(gold_path, 'w') as save_gold:\n","        for i, idx in enumerate(list_out):\n","            _pred = []\n","            newDict = dict()\n","            if(len(src_txt[i])==0):\n","                continue\n","            for j in list_out[i][:len(src_txt[i])]:\n","                # print(i,j)\n","                if(j>=len( src_txt[i])):\n","                    continue\n","                candidate = src_txt[i][j].strip()\n","\n","                if(not _block_tri(candidate,_pred)):\n","                    _pred.append(candidate)\n","                    newDict.update({j:candidate})\n","                if len(_pred) == len(tgt_txt[i].split(\"<q>\")):\n","                    break\n","                # else:\n","                #     _pred.append(candidate)\n","            pred.append(_pred)\n","            gold.append(tgt_txt[i].replace(\"<q>\",\" \"))\n","            pred_keys.append(newDict)\n","        for i in range(len(gold)):\n","            save_gold.write(gold[i].strip() +'\\n')\n","\n","        for i in range(len(pred)):\n","            # idx = []\n","            # for x in pred_keys[i]:\n","            #     idx.append(x)\n","            # idx.sort()\n","            # str_out = \"\"\n","            # for x in idx:\n","            #     str_out += pred_keys[i][x] + ' '\n","            # save_pred.write(str_out.strip()+'\\n')\n","            save_pred.write(' '.join(pred[i]).strip()+'\\n')\n","\n","        # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yJ6_eMZi8J6"},"source":["list_candidate = []\n","list_gold = []\n","for x in open(gold_path):\n","    list_gold.append(x.replace(\"\\n\",\"\"))\n","for x in open(can_path):\n","    list_candidate.append(x.replace(\"\\n\",\"\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2lZzd50tioi4"},"source":["# Sử dụng độ đo ROUGE để đánh giá hiệu suất"]},{"cell_type":"code","metadata":{"id":"61ob1kV-TEQA"},"source":["!pip install rouge-score\n","!pip install rouge/requirements.txt\n","from rouge_score import rouge_scorer\n","\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL','rouge2'], use_stemmer=True)\n","scores = scorer.score('The quick brown fox jumps over the lazy dog',\n","                      'The quick brown dog jumps on the log.')\n","scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndmLHtp5lcHD"},"source":["from rouge_score import rouge_scorer\n","\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL','rouge2'], use_stemmer=True)\n","# scores = scorer.score('The quick brown fox jumps over the lazy dog',\n","#                       'The quick brown dog jumps on the log.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVwtMJdlXHsw"},"source":["import pandas as pd\n","data  = pd.read_csv('/content/drive/MyDrive/Pro2/wikiP1.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luKOvWQ0linC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622814200731,"user_tz":-420,"elapsed":27582,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"93f1a049-a207-478c-8e83-10e4feecafb1"},"source":["sum_rouge1 = sum_rougeL=sum_rouge2 = 0\n","for i in range(25000):\n","    if i % 1000==0:\n","            print(i)\n","    scores = scorer.score(list_candidate[i],\n","                      list_gold[i].replace(\"<q>\",\" \"))\n","    if i % 1000 ==0:\n","        print( scores['rouge1'][2],scores['rougeL'][2],scores['rouge2'][2])\n","    sum_rouge1  += scores['rouge1'][2]\n","    sum_rougeL += scores['rougeL'][2]\n","    sum_rouge2 += scores['rouge2'][2]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19000\n","0.2417582417582418 0.14285714285714288 0.07777777777777779\n","20000\n","0.23140495867768593 0.11570247933884296 0.03361344537815126\n","21000\n","0.23963133640552992 0.1382488479262673 0.04651162790697674\n","22000\n","0.2413793103448276 0.13793103448275862 0.0\n","23000\n","0.23255813953488372 0.13953488372093023 0.09523809523809523\n","24000\n","0.24096385542168672 0.14457831325301204 0.07407407407407408\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AFHXkYcbijgL"},"source":["# Kết quả"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVr7n1fAmrCy","executionInfo":{"status":"ok","timestamp":1622814200732,"user_tz":-420,"elapsed":15,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"db588d4a-ad9d-4728-9029-cc6cd39db5c2"},"source":["(sum_rouge1/25000*100,sum_rouge2/25000*100, sum_rougeL/25000*100)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29.301154408172042, 8.038535401516198, 17.5276467862946)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"fi-7_giksuxY"},"source":[""],"execution_count":null,"outputs":[]}]}