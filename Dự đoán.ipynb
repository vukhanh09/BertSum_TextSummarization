{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dự đoán.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1CiU1QsTye4PVGiBhAdgevDI6IGWoFccy","authorship_tag":"ABX9TyOEsfvUo86EdGgigT8dkkmG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b88a46ccd68e401eb35f020f4d2f1e99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ba63cf79ebb4d02bb279cc9a202ce2f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8dfbc3818084432cbf8a0762451ca38f","IPY_MODEL_2f093fd68201437b85363b967bc1b45b"]}},"5ba63cf79ebb4d02bb279cc9a202ce2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dfbc3818084432cbf8a0762451ca38f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_129b85162d3842a0b71e6e85634e1cf1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_711d9ffad90f494bbabc4de482ebb235"}},"2f093fd68201437b85363b967bc1b45b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e596fd063b94bc0a6a103445607b0e7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/? [01:16&lt;00:00, 76.02s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ad6cf241ddd468e8bcdca26848ea4b3"}},"129b85162d3842a0b71e6e85634e1cf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"711d9ffad90f494bbabc4de482ebb235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e596fd063b94bc0a6a103445607b0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ad6cf241ddd468e8bcdca26848ea4b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"JtFAEfpbOjtv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626427558147,"user_tz":-420,"elapsed":46863,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"4694be10-b2f3-40f1-d11f-8ccf59018cf1"},"source":["# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl\n","!pip install transformers\n","from transformers import BertTokenizer\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","import re\n","import pandas as pd\n","import torch\n","import numpy as np\n","from tqdm import tqdm_notebook\n","# import torch_xla.utils.serialization as xser\n","import torch.nn as nn\n","!pip install pytorch_pretrained_bert\n","from pytorch_pretrained_bert import BertModel, BertConfig\n","from torch.nn.init import xavier_uniform_\n","\n","from __future__ import division\n","\n","import argparse\n","import glob\n","import os\n","import random\n","import signal\n","import time\n","\n","import distributed\n","# import torch_xla.core.xla_model as xm\n","# import torch_xla.distributed.parallel_loader as pl\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","\n","import gensim.downloader as api\n","word_vectors = api.load(\"glove-wiki-gigaword-100\")\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import pairwise_distances_argmin_min"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Requirement already satisfied: botocore<1.22.0,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.21.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.5.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.0->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.0->boto3->pytorch_pretrained_bert) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Cb7HAUTO123"},"source":["class BertData():\n","    def __init__(self):\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","        self.sep_vid = self.tokenizer.vocab['[SEP]']\n","        self.cls_vid = self.tokenizer.vocab['[CLS]']\n","        self.pad_vid = self.tokenizer.vocab['[PAD]']\n","        self.min_nsents = 3\n","        self.max_nsents = 100\n","        self.min_src_ntokens = 3\n","        self.max_src_ntokens = 200\n","\n","\n","    def preprocess(self, src):\n","\n","        if (len(src) == 0):\n","            return None\n","\n","        original_src_txt = [' '.join(s) for s in src]\n","\n","\n","        idxs = [i for i, s in enumerate(src) if (len(s) > self.min_src_ntokens)]\n","        # print('idxs:',idxs)\n","\n","        src = [src[i][:self.max_src_ntokens] for i in idxs]\n","\n","        src = src[:self.max_nsents]\n","\n","        if (len(src) < self.min_nsents):\n","            return None\n","\n","\n","        src_txt = [' '.join(sent) for sent in src]\n","\n","        text = ' [SEP] [CLS] '.join(src_txt)\n","        src_subtokens = self.tokenizer.tokenize(text)\n","        src_subtokens = src_subtokens[:510]\n","        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n","\n","        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n","        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n","        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n","        segments_ids = []\n","        for i, s in enumerate(segs):\n","            if (i % 2 == 0):\n","                segments_ids += s * [0]\n","            else:\n","                segments_ids += s * [1]\n","        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n","\n","\n","        src_txt = [original_src_txt[i] for i in idxs]\n","        return src_subtoken_idxs, segments_ids, cls_ids, src_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Luye6J8bJ5Kj"},"source":["class Classifier(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(Classifier, self).__init__()\n","        self.linear1 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x, mask_cls):\n","        h = self.linear1(x).squeeze(-1)\n","        sent_scores = self.sigmoid(h) * mask_cls.float()\n","        return sent_scores\n","class Bert(nn.Module):\n","    def __init__(self, temp_dir, load_pretrained_bert, bert_config):\n","        super(Bert, self).__init__()\n","        if(load_pretrained_bert):\n","            self.model = BertModel.from_pretrained('bert-base-uncased', cache_dir=temp_dir)\n","        else:\n","            self.model = BertModel(bert_config)\n","\n","    def forward(self, x, segs, mask):\n","        encoded_layers, _ = self.model(x, segs, attention_mask =mask)\n","        top_vec = encoded_layers[-1]\n","        return top_vec\n","\n","\n","temp_dir = '/content/drive/MyDrive/Pro2/temp'\n","class Summarizer(nn.Module):\n","    def __init__(self,device, load_pretrained_bert = False, bert_config = None):\n","        super(Summarizer, self).__init__()\n","        self.bert = Bert(temp_dir, load_pretrained_bert, bert_config)\n","        \n","        self.encoder = Classifier(self.bert.model.config.hidden_size)\n","        \n","\n","      \n","        for p in self.encoder.parameters():\n","            if p.dim() > 1:\n","                xavier_uniform_(p)\n","\n","        self.to(device)\n","    def load_cp(self, pt):\n","        self.load_state_dict(pt, strict=True)\n","\n","    def forward(self, x, segs, clss, mask, mask_cls, sentence_range=None):\n","\n","        top_vec = self.bert(x, segs, mask)\n","        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n","        sents_vec = sents_vec * mask_cls[:, :, None].float()\n","        sent_scores = self.encoder(sents_vec, mask_cls).squeeze(-1)\n","        return sent_scores, mask_cls\n","def train(device,train_from):\n","\n","    model = Summarizer(device, load_pretrained_bert=True)\n","    \n","    if train_from != '':\n","        checkpoint = torch.load(train_from)\n","        model.load_cp(checkpoint)\n","        # optim = build_optim(train_from, model, checkpoint)\n","        checkpoint = 0\n","    # else:\n","    #     optim = build_optim(train_from,model, None)\n"," \n","    return model\n","    # model,optim\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUrpjE8xQeyv"},"source":["bert = BertData()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBJspmbHPgRG"},"source":["def convert1(datasets):\n","    def _pad(data, pad_id, width=-1):\n","        if (width == -1):\n","            width = max(len(d) for d in data)\n","        rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n","        return rtn_data\n","    pre_src = [x['src'] for x in datasets[:]]\n","\n","    pre_segs = [x['segs'] for x in datasets[:]]\n","    pre_clss = [x['clss'] for x in datasets[:]]\n","    src_txt = [x['src_txt'] for x in datasets[:]]\n","\n","    src = torch.tensor(_pad(pre_src, 0))\n","\n","\n","    segs = torch.tensor(_pad(pre_segs, 0))\n","    mask = ~(src == 0)\n","\n","    clss = torch.tensor(_pad(pre_clss, -1))\n","    mask_cls = ~ (clss == -1)\n","    clss[clss == -1] = 0\n","\n","\n","\n","    return src,segs,clss,mask,mask_cls,src_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MT4mLotvP6g9"},"source":["def _get_ngrams(n, text):\n","            ngram_set = set()\n","            text_length = len(text)\n","            max_index_ngram_start = text_length - n\n","            for i in range(max_index_ngram_start + 1):\n","                ngram_set.add(tuple(text[i:i + n]))\n","            return ngram_set\n","\n","def _block_tri(c, p):\n","    tri_c = _get_ngrams(3, c.split())\n","    for s in p:\n","        tri_s = _get_ngrams(3, s.split())\n","        if len(tri_c.intersection(tri_s))>0:\n","            return True\n","    return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUEywpxNnLCC"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0ifrEBHnQBN","executionInfo":{"status":"ok","timestamp":1626427559475,"user_tz":-420,"elapsed":8,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"b8e6010b-27bb-4686-c6d0-cd3a6604f805"},"source":["device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"TIHIgQMZnJCd"},"source":["path ='/content/drive/MyDrive/Pro2/WeightBert/bertWeight1'\n","checkpoint = torch.load(path)\n","model = train(device,'')\n","model.load_cp(checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqANLdACPJTJ"},"source":["def BertSumSummary(X):\n","    datasets = []\n","    source = sent_tokenize(X)\n","    source = [word_tokenize(word) for word in source]\n","    b_data = bert.preprocess(source)\n","    if (b_data is None):\n","        print('None data')\n","    indexed_tokens, segments_ids, cls_ids, src_txt = b_data\n","    b_data_dict = {\"src\": indexed_tokens, \"segs\": segments_ids, 'clss': cls_ids,\n","                    'src_txt': src_txt}\n","    datasets.append(b_data_dict)\n","    src,segs,clss,mask,mask_cls, src_txt = convert1(datasets)\n","    ##load model\n","\n","    # path ='/content/drive/MyDrive/Pro2/WeightBert/bertWeight1'\n","    # checkpoint = xser.load(path)\n","    # device = xm.xla_device()\n","    # model = train(device,'')\n","    # model.load_cp(checkpoint)\n","    batch_size = 1\n","    train_data = TensorDataset(src,segs,clss,mask,mask_cls)\n","    train_sampler = SequentialSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","    ## predict \n","    list_selected_ids = []\n","    with torch.no_grad():\n","      for step, batch in tqdm_notebook(enumerate(train_dataloader)):\n","\n","          src = batch[0].to(device)\n","          segs = batch[1].to(device)\n","          clss = batch[2].to(device)\n","          mask = batch[3].to(device)\n","          mask_cls = batch[4].to(device)\n","          sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","      \n","          sent_scores = sent_scores + mask.float()\n","\n","          sent_scores = sent_scores.cpu().data.numpy()\n","          selected_ids = np.argsort(-sent_scores, 1)\n","          list_selected_ids.append(selected_ids)\n","          # xm.mark_step()\n","    list_out = list_selected_ids[0]\n","    for i, idx in enumerate(list_selected_ids[1:]):\n","        print(list_out.shape)\n","        print(idx.shape)\n","        list_out = np.concatenate((list_out,idx),axis=0)\n","    # list_out.shape\n","    pred = []\n","    for i, idx in enumerate(list_out):\n","        _pred = []\n","        newDict = dict()\n","        if(len(src_txt[i])==0):\n","            continue\n","        for j in list_out[i][:len(src_txt[i])]:\n","            # print(i,j)\n","            if(j>=len( src_txt[i])):\n","                continue\n","            candidate = src_txt[i][j].strip()\n","\n","            if(not _block_tri(candidate,_pred)):\n","                _pred.append(candidate)\n","                newDict.update({j:candidate})\n","            if len(_pred) == 5:\n","                break\n","            # else:\n","            #     _pred.append(candidate)\n","        pred.append(newDict)\n","    idx = []\n","    for x in pred[0]:\n","        idx.append(x)\n","    idx.sort()\n","    str_out = \"\"\n","    for x in idx:\n","        str_out += pred[0][x] + ' '\n","    return str_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_OVfPT7Rx6A"},"source":["data  = pd.read_csv('/content/drive/MyDrive/Pro2/wikiP1.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"MegsD5HlLKOO","executionInfo":{"status":"ok","timestamp":1626427582866,"user_tz":-420,"elapsed":31,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"232898ee-d4e7-4d0d-95c4-dabbe0f40ea4"},"source":["data.iloc[101]['text']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' As you move forward in the letter, be upfront about your feelings. A love letter is not the place to be shy. Tell the girl why you admire her and what qualities about her most intrigue you. Go into specifics when possible. You may not know a lot about this person, but mention small things about her that you love. For example, maybe you think the buttons she has on her purse are hilarious. Maybe you notice she listens to a particular band on her headphones that you also enjoy.\\n\\n\\nBe upfront about why you\\'ve never approached her in person. While many people enjoy anonymous love letters, there is always the risk of coming off the wrong way. You don\\'t want the recipient to feel like she\\'s being watched. It can help if you assure her, at some point, you\\'re a relatively normal person who happens to feel more comfortable expressing feelings in writing.There are a variety of reasons you may prefer writing a love letter. You could be shy, for example, and find expressing yourself easier in words. Maybe you only see her when she\\'s at work and don\\'t want to bother her. Whatever you reason, make sure you state it early on. You want to make sure the recipient understands why you chose a letter over simply talking to her. This way, you can help avoid potential confusion or discomfort.Returning to the example of the girl you know in algebra class, you may hesitate to approach her because you\\'re shy. You could write something like, \"I always want to talk to you in person. However, I\\'m very shy by nature. Now that we\\'re halfway through the semester, I\\'m worried I\\'ll never get the courage together. So, I decided to write you a letter.\"\\n\\n, Oftentimes, people end up inadvertently talking about themselves in a love letter. While you should certainly talk about your own feelings, make sure to focus primarily on the recipient. As you write the letter, express what you like about this person. If you admire that she\\'s always listening to Elliot Smith on her headphones, say so. However, do not go on a 3 paragraph anecdote about your own admiration for Smith.Use specifics when possible. If you\\'re writing to a relative stranger, specifics may be hard. However, small things go a long way. Do you love the coconut-like smell of her shampoo? Do you enjoy how she laughs to herself during downtime at the coffee shop? Do you remember a comment she made in class that was particularly insightful?\\nLet\\'s return to the algebra class example. You could write something like, \"I notice you\\'re always listening to Elliot Smith. I am a big fan of his as well. I\\'m impressed by how drawn in you seem to the music. You seem to have an intense appreciation for art.\"\\n\\n, You don\\'t have to write in a lofty, elevated style if it doesn\\'t come naturally to you. The primary purpose of a love letter is to express your feelings in a way that makes the recipient feel good about herself. The best way to do this is to simply be yourself and use your own words. This will sound more authentic and sincere when expressed in a way that feels natural to you. Do not get hung up on inserting elaborate metaphors or dramatic declarations of your admiration into your writing. Instead, focus on simply being yourself and speaking in your own voice., As you near the end of your letter, tell the person how their presence has affected you. The girl you\\'re writing to may be flattered to know she made an impact on your life. Talk about how she makes your days better and why you appreciate her.This may be something small, as you don\\'t know this girl yet. However, even a small impact can be flattering. For example, maybe you always look forward to your 8AM British Literature seminar simply because you enjoy the contributions this girl makes to class.\\nReturning to are example, you could write something like, \"I know it sounds silly, but getting to see you each day makes me a bit more enthusiastic about going to algebra. I\\'ve never been a math person, but seeing you is a small treat that makes class more bearable.\"\\n\\n'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"VtAOjZPCT489","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626427588302,"user_tz":-420,"elapsed":5442,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"f9be77e6-0407-4934-b560-7a5d3bcb2e83"},"source":["!pip install gevent\n","!pip install flask_ngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gevent in /usr/local/lib/python3.7/dist-packages (21.1.2)\n","Requirement already satisfied: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent) (4.5.0)\n","Requirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent) (57.0.0)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent) (5.4.0)\n","Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.5.30)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s6xD-YC_bc5O"},"source":["vocab = word_vectors.vocab\n","\n","n_clusters = 5\n","\n","kmeans = KMeans(n_clusters=n_clusters)\n","def clearData(content):\n","    content = content.lower() #Biến đổi hết thành chữ thường\n","    content = content.replace('\\n', ' ') #Đổi các ký tự xuống dòng thành chấm câu\n","    content = content.replace(',', '') \n","    content = content.replace(':', '')\n","    content = content.strip()\n","    return content\n","def clearData1(content):\n","    content = content.replace('\\n', ' ') #Đổi các ký tự xuống dòng thành chấm câu\n","    content = content.replace(',', '') \n","    content = content.replace(':', '')\n","    content = content.strip()\n","    return content\n","def KmeanSumary(text):\n","    content = clearData(text)\n","    sentences = nltk.sent_tokenize(content)\n","\n","    original = clearData1(text)\n","    original = nltk.sent_tokenize(original)\n","    if(len(sentences)<5):\n","        print(\"article less more than 5 sentences\")\n","    X = []\n","    for sentence in sentences:\n","        sentence_tokenized = word_tokenize(sentence)\n","        # words = sentence_tokenized.split(\" \")\n","        sentence_vec = np.zeros((100))\n","        for word in sentence_tokenized:\n","            if word in vocab:\n","                sentence_vec += word_vectors[word]\n","        X.append(sentence_vec)\n","    pred = kmeans.fit(X)\n","    avg = []\n","    for j in range(n_clusters):\n","        idx = np.where(pred.labels_ == j)[0]\n","        avg.append(np.mean(idx))\n","    closest, _ = pairwise_distances_argmin_min(pred.cluster_centers_, X)\n","    ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n","    summary = ' '.join([original[closest[idx]] for idx in ordering])\n","    return summary\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455,"referenced_widgets":["b88a46ccd68e401eb35f020f4d2f1e99","5ba63cf79ebb4d02bb279cc9a202ce2f","8dfbc3818084432cbf8a0762451ca38f","2f093fd68201437b85363b967bc1b45b","129b85162d3842a0b71e6e85634e1cf1","711d9ffad90f494bbabc4de482ebb235","7e596fd063b94bc0a6a103445607b0e7","4ad6cf241ddd468e8bcdca26848ea4b3"]},"id":"ILACllwqT8-3","executionInfo":{"status":"ok","timestamp":1626427703100,"user_tz":-420,"elapsed":114834,"user":{"displayName":"khánh vũ","photoUrl":"","userId":"11152008338904038994"}},"outputId":"70288524-b13f-46d9-9e20-ce2917647510"},"source":["from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","from http.client import error\n","from flask import Flask\n","from gevent.pywsgi import WSGIServer\n","from flask import request, jsonify, render_template\n","\n","app = Flask(__name__, template_folder='/content/drive/MyDrive/Pro2/templates') \n","run_with_ngrok(app)\n","\n","@app.route('/', methods=['GET'])\n","def index1():\n","    return render_template('index.html')\n","\n","@app.route('/', methods=['GET', 'POST'])\n","def my_form_post():\n","    text = request.form.get(\"message\")\n","    option = request.form.getlist('options')\n","    if len(option) == 0 :\n","        print(\"BertSum predicting...\")\n","        output =\"BertSum prediction:\"+ \"\\n\" + BertSumSummary(text)\n","    elif option[0] =='option1':\n","        print(\"BertSum predicting...\")\n","        output = \"BertSum prediction:\"+ \"\\n\" + BertSumSummary(text)\n","    else:\n","        print(\"Kmeans predicting...\")\n","        output = \"Kmean prediction:\" + \"\\n\" + KmeanSumary(text)\n","\n","    print(output)\n","    list_out = []\n","    list_out.append(text)\n","    list_out.append(output)\n","    return render_template('index1.html',errors = list_out)\n","\t\n","app.run()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://5d6b02cfa45b.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [16/Jul/2021 09:26:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [16/Jul/2021 09:26:57] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"},{"output_type":"stream","text":["BertSum predicting...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b88a46ccd68e401eb35f020f4d2f1e99","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["127.0.0.1 - - [16/Jul/2021 09:27:06] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"},{"output_type":"stream","text":["\n","BertSum prediction:\n","; , Some studios offer short-term programs for people who want to learn more about VFX artistry without pursuing a college degree . Stay informed about the newest software advances by following VFX blogs and taking online computer tutorials.For example , VFX artists are expected to be well-versed in graphics and animation programs , such as Adobe Creative Suite and JavaScript.Clearly list every program that you can work with on your resume . , Watch all of these creations with an eye for detail . Look for the techniques used and any original approaches that you see . Try to recreate any scenes that you find particularly interesting . \n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [16/Jul/2021 09:27:07] \"\u001b[33mGET /main.css HTTP/1.1\u001b[0m\" 404 -\n","127.0.0.1 - - [16/Jul/2021 09:27:13] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"},{"output_type":"stream","text":["Kmeans predicting...\n","Kmean prediction:\n","Stay informed about the newest software advances by following VFX blogs and taking online computer tutorials.For example VFX artists are expected to be well-versed in graphics and animation programs such as Adobe Creative Suite and JavaScript.Clearly list every program that you can work with on your resume. Even geometry skills can come in handy when creating a particular type of background or even a person’s face.Make a choice to become an observer of the world around you. As you gain more experience you’ll likely find yourself gravitating toward a certain aspect of design. Some of these videos will focus on a particular skill set such as shading which you then can practice on your own. Watch all of these creations with an eye for detail.\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [16/Jul/2021 09:27:14] \"\u001b[33mGET /main.css HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"}]}]}